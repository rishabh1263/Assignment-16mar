{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0860d0b",
   "metadata": {},
   "source": [
    "Q1:\n",
    "Overfitting\n",
    "Overfitting occurs when our machine learning model tries to cover all the data points or more than the required data points present in the given dataset. Because of this, the model starts caching noise and inaccurate values present in the dataset, and all these factors reduce the efficiency and accuracy of the model. The overfitted model has low bias and high variance.\n",
    "\n",
    "The chances of occurrence of overfitting increase as much we provide training to our model. It means the more we train our model, the more chances of occurring the overfitted model.\n",
    "\n",
    "Overfitting is the main problem that occurs in supervised learning.\n",
    "\n",
    "Underfitting\n",
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data. As a result, it may fail to find the best fit of the dominant trend in the data.\n",
    "\n",
    "In the case of underfitting, the model is not able to learn enough from the training data, and hence it reduces the accuracy and produces unreliable predictions.\n",
    "\n",
    "An underfitted model has high bias and low variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e4760",
   "metadata": {},
   "source": [
    "Q2:\n",
    "You can prevent overfitting by diversifying and scaling your training data set or using some other data science strategies, like those given below.\n",
    "Early stopping. Early stopping pauses the training phase before the machine learning model learns the noise in the data. ...\n",
    "Pruning. ...\n",
    "Regularization. ...\n",
    "Ensembling. ...\n",
    "Data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6ebc8",
   "metadata": {},
   "source": [
    "Q3:\n",
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845ec6a",
   "metadata": {},
   "source": [
    "Q4:\n",
    "Whenever we discuss model prediction, it’s important to understand prediction errors (bias and variance). There is a tradeoff between a model’s ability to minimize bias and variance. Gaining a proper understanding of these errors would help us not only to build accurate models but also to avoid the mistake of overfitting and underfitting.\n",
    "\n",
    "So let’s start with the basics and see how they make difference to our machine learning Models.\n",
    "\n",
    "What is bias?\n",
    "\n",
    "Bias is the difference between the average prediction of our model and the correct value which we are trying to predict. Model with high bias pays very little attention to the training data and oversimplifies the model. It always leads to high error on training and test data.\n",
    "\n",
    "What is variance?\n",
    "\n",
    "Variance is the variability of model prediction for a given data point or a value which tells us spread of our data. Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasn’t seen before. As a result, such models perform very well on training data but has high error rates on test data.\n",
    "\n",
    "Mathematically\n",
    "\n",
    "Let the variable we are trying to predict as Y and other covariates as X. We assume there is a relationship between the two such that\n",
    "\n",
    "Y=f(X) + e\n",
    "\n",
    "Where e is the error term and it’s normally distributed with a mean of 0.\n",
    "\n",
    "We will make a model f^(X) of f(X) using linear regression or any other modeling technique.\n",
    "\n",
    "So the expected squared error at a point x is\n",
    "\n",
    "\n",
    "The Err(x) can be further decomposed as\n",
    "\n",
    "\n",
    "Err(x) is the sum of Bias², variance and the irreducible error.\n",
    "\n",
    "Irreducible error is the error that can’t be reduced by creating good models. It is a measure of the amount of noise in our data. Here it is important to understand that no matter how good we make our model, our data will have certain amount of noise or irreducible error that can not be removed.\n",
    "\n",
    "Bias and variance using bulls-eye diagram\n",
    "\n",
    "\n",
    "In the above diagram, center of the target is a model that perfectly predicts correct values. As we move away from the bulls-eye our predictions become get worse and worse. We can repeat our process of model building to get separate hits on the target.\n",
    "\n",
    "In supervised learning, underfitting happens when a model unable to capture the underlying pattern of the data. These models usually have high bias and low variance. It happens when we have very less amount of data to build an accurate model or when we try to build a linear model with a nonlinear data. Also, these kind of models are very simple to capture the complex patterns in data like Linear and logistic regression.\n",
    "\n",
    "In supervised learning, overfitting happens when our model captures the noise along with the underlying pattern in data. It happens when we train our model a lot over noisy dataset. These models have low bias and high variance. These models are very complex like Decision trees which are prone to overfitting.\n",
    "\n",
    "\n",
    "Why is Bias Variance Tradeoff?\n",
    "\n",
    "If our model is too simple and has very few parameters then it may have high bias and low variance. On the other hand if our model has large number of parameters then it’s going to have high variance and low bias. So we need to find the right/good balance without overfitting and underfitting the data.\n",
    "\n",
    "This tradeoff in complexity is why there is a tradeoff between bias and variance. An algorithm can’t be more complex and less complex at the same time.\n",
    "\n",
    "Total Error\n",
    "\n",
    "To build a good model, we need to find a good balance between bias and variance such that it minimizes the total error.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88439a04",
   "metadata": {},
   "source": [
    "Q5:\n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4182d19",
   "metadata": {},
   "source": [
    "Q6:\n",
    "What is the difference between high bias and high variance in machine learning?\n",
    "A model with high variance may represent the data set accurately but could lead to overfitting to noisy or otherwise unrepresentative training data. In comparison, a model with high bias may underfit the training data due to a simpler model that overlooks regularities in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3b757d",
   "metadata": {},
   "source": [
    "Q7:\n",
    "What is regularization in machine learning and how can it be used to prevent overfitting describe some common regularization techniques and how they work?\n",
    "Image result for Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work.\n",
    "Regularization is a technique that adds information to a model to prevent the occurrence of overfitting. It is a type of regression that minimizes the coefficient estimates to zero to reduce the capacity (size) of a model. In this context, the reduction of the capacity of a model involves the removal of extra weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941d308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
